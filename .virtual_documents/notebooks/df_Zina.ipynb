import pandas as pd

df_demo = pd.read_csv("/Users/ZINA/Desktop/IRONHACK/Week_5/Project/df_final_demo.txt")
df_web1 = pd.read_csv("/Users/ZINA/Desktop/IRONHACK/Week_5/Project/df_final_web_data_pt_1.txt")
df_web2 = pd.read_csv("/Users/ZINA/Desktop/IRONHACK/Week_5/Project/df_final_web_data_pt_2.txt")
df_exp = pd.read_csv("/Users/ZINA/Desktop/IRONHACK/Week_5/Project/df_final_experiment_clients.txt")


df_demo.head()


df_demo.info()


# 70609 clients 
# only gender column is an object (string)
# 14-15 missing rows per column : dataset is largely complete with very few missing values
# clnt_tenure_yr/clnt_tenure_mnth : how long they have been clients
# num_accts = number of accounts


df_demo.isna().sum()


df_demo["gendr"].unique() # Gender has inconsistent labels


df_demo['gendr'].value_counts() # U = unknown data is very large : 24122


# creating a clean age column (for clarity only no changes made)
df_demo['gender_clean'] = df_demo['gendr'].replace({'M': 'Male','F': 'Female','U': 'Unknown','X': 'Other'})
df_demo['gender_clean'] = df_demo['gender_clean'].fillna('Unknown')
df_demo                                                    


df_demo['gender_clean'].isna().sum() # to check


df_web1.head()


df_web1.info()





df_web2.head()


df_web2.info()





df_exp.head()


df_exp.info()


# 70609 entries : same as number of clients in df_demo
# variation : 20109 missing data 





# Concatenating the two web datasets 
df_web = pd.concat([df_web1, df_web2], axis=0)


df_web.head()


df_web.info()


# 755405 entries : no missing values 
# multiple rows per client : behavioral events
# date_time column is an object : needs to be converted 


# convert date_time column from object to a datetime
df_web['date_time'] = pd.to_datetime(df_web['date_time'])


# checking if datetime conversion worked : 
df_web.info()


df_web['process_step'].value_counts()


df_web['client_id'].nunique()


df_web['visit_id'].nunique()



